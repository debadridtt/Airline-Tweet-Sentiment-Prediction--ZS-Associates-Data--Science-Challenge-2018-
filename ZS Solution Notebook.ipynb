{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'test.csv', 'train.csv', 'tweet.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"D:/Datasets/zs2\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tr_tweet_1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tr_tweet_2</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tr_tweet_3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tr_tweet_4</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tr_tweet_5</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id airline_sentiment  airline_sentiment_confidence negativereason  \\\n",
       "0  Tr_tweet_1           neutral                        1.0000            NaN   \n",
       "1  Tr_tweet_2          positive                        0.3486            NaN   \n",
       "2  Tr_tweet_3           neutral                        0.6837            NaN   \n",
       "3  Tr_tweet_4          negative                        1.0000     Bad Flight   \n",
       "4  Tr_tweet_5          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason_confidence         airline        name  retweet_count  \\\n",
       "0                        NaN  Virgin America     cairdin            0.0   \n",
       "1                     0.0000  Virgin America    jnardino            0.0   \n",
       "2                        NaN  Virgin America  yvonnalynn            0.0   \n",
       "3                     0.7033  Virgin America    jnardino            0.0   \n",
       "4                     1.0000  Virgin America    jnardino            0.0   \n",
       "\n",
       "                                                text  \\\n",
       "0                @VirginAmerica What @dhepburn said.   \n",
       "1  @VirginAmerica plus you've added commercials t...   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3  @VirginAmerica it's really aggressive to blast...   \n",
       "4  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_tweet_1</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>pilot</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>2015-02-24 11:12:29 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_tweet_2</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>idk_but_youtube</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica did you know that suicide is th...</td>\n",
       "      <td>2015-02-24 10:48:24 -0800</td>\n",
       "      <td>1/1 loner squad</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_tweet_3</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>mollanderson</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #f...</td>\n",
       "      <td>2015-02-24 10:21:28 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_tweet_4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>heatherovieda</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "      <td>2015-02-24 09:39:46 -0800</td>\n",
       "      <td>this place called NYC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_tweet_5</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>KGervaise</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I have an unused ticket but mov...</td>\n",
       "      <td>2015-02-23 16:20:38 -0800</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id  airline_sentiment_confidence negativereason  \\\n",
       "0  Test_tweet_1                        0.6340            NaN   \n",
       "1  Test_tweet_2                        0.6769            NaN   \n",
       "2  Test_tweet_3                        0.6451            NaN   \n",
       "3  Test_tweet_4                        1.0000     Bad Flight   \n",
       "4  Test_tweet_5                        0.6578            NaN   \n",
       "\n",
       "   negativereason_confidence         airline             name  retweet_count  \\\n",
       "0                        NaN  Virgin America            pilot              0   \n",
       "1                        0.0  Virgin America  idk_but_youtube              0   \n",
       "2                        NaN  Virgin America     mollanderson              0   \n",
       "3                        1.0  Virgin America    heatherovieda              0   \n",
       "4                        0.0  Virgin America        KGervaise              0   \n",
       "\n",
       "                                                text  \\\n",
       "0  @VirginAmerica Really missed a prime opportuni...   \n",
       "1  @VirginAmerica did you know that suicide is th...   \n",
       "2  @VirginAmerica @virginmedia I'm flying your #f...   \n",
       "3  @VirginAmerica  I flew from NYC to SFO last we...   \n",
       "4  @VirginAmerica I have an unused ticket but mov...   \n",
       "\n",
       "               tweet_created         tweet_location  \\\n",
       "0  2015-02-24 11:12:29 -0800            Los Angeles   \n",
       "1  2015-02-24 10:48:24 -0800        1/1 loner squad   \n",
       "2  2015-02-24 10:21:28 -0800                    NaN   \n",
       "3  2015-02-24 09:39:46 -0800  this place called NYC   \n",
       "4  2015-02-23 16:20:38 -0800                Georgia   \n",
       "\n",
       "                user_timezone  \n",
       "0  Pacific Time (US & Canada)  \n",
       "1  Eastern Time (US & Canada)  \n",
       "2  Eastern Time (US & Canada)  \n",
       "3  Eastern Time (US & Canada)  \n",
       "4  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv('test.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                         object\n",
       "airline_sentiment                object\n",
       "airline_sentiment_confidence    float64\n",
       "negativereason                   object\n",
       "negativereason_confidence       float64\n",
       "airline                          object\n",
       "name                             object\n",
       "retweet_count                   float64\n",
       "text                             object\n",
       "tweet_created                    object\n",
       "tweet_location                   object\n",
       "user_timezone                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3339, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            2884\n",
       "Virgin America     454\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                           0\n",
       "airline_sentiment                  0\n",
       "airline_sentiment_confidence       0\n",
       "negativereason                  1205\n",
       "negativereason_confidence        889\n",
       "airline                            1\n",
       "name                               1\n",
       "retweet_count                      1\n",
       "text                               1\n",
       "tweet_created                     96\n",
       "tweet_location                  1020\n",
       "user_timezone                   1108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                          0\n",
       "airline_sentiment_confidence      0\n",
       "negativereason                  117\n",
       "negativereason_confidence        82\n",
       "airline                           0\n",
       "name                              0\n",
       "retweet_count                     0\n",
       "text                              0\n",
       "tweet_created                    10\n",
       "tweet_location                  111\n",
       "user_timezone                   123\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['name','tweet_location','user_timezone','tweet_created','negativereason'],axis=1,inplace=True)\n",
    "\n",
    "df2.drop(['name','tweet_location','user_timezone','tweet_created','negativereason'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['negativereason_confidence']=df['negativereason_confidence'].fillna(df['negativereason_confidence'].mean())\n",
    "df2['negativereason_confidence']=df2['negativereason_confidence'].fillna(df2['negativereason_confidence'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                        0\n",
       "airline_sentiment               0\n",
       "airline_sentiment_confidence    0\n",
       "negativereason_confidence       0\n",
       "airline                         0\n",
       "retweet_count                   0\n",
       "text                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                        0\n",
       "airline_sentiment_confidence    0\n",
       "negativereason_confidence       0\n",
       "airline                         0\n",
       "retweet_count                   0\n",
       "text                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(df['text']) is str:\n",
    "        df['text'] = df['text'].lower()\n",
    "        \n",
    "        \n",
    "if type(df2['text']) is str:\n",
    "        df2['text'] = df2['text'].lower()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dutta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "import string\n",
    "def clean_text(text):\n",
    "    \n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    \n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    ## Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    ## Stemming\n",
    "    text = text.split()\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "    return text\n",
    "\n",
    "df['text']=df['text'].apply(clean_text)\n",
    "df2['text']=df2['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    2134\n",
       "neutral      679\n",
       "positive     525\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df.airline_sentiment==\"negative\"]\n",
    "df_minority_1 = df[df.airline_sentiment==\"neutral\"]\n",
    "df_minority_2 = df[df.airline_sentiment==\"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_1_upsampled = resample(df_minority_1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=2134,    # to match majority class\n",
    "                                 random_state=50) \n",
    "\n",
    "\n",
    "df_minority_2_upsampled = resample(df_minority_2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=2134,    # to match majority class\n",
    "                                 random_state=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_majority, df_minority_1_upsampled,df_minority_2_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     2134\n",
       "positive    2134\n",
       "negative    2134\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tr_tweet_4</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica realli aggress blast obnoxi ente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tr_tweet_5</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica realli big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tr_tweet_6</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica serious would pay 30 flight seat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tr_tweet_13</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica sfo - pdx schedul still mia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tr_tweet_17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.3614</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica first fare may three time carrie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "3    Tr_tweet_4          negative                        1.0000   \n",
       "4    Tr_tweet_5          negative                        1.0000   \n",
       "5    Tr_tweet_6          negative                        1.0000   \n",
       "12  Tr_tweet_13          negative                        0.6842   \n",
       "16  Tr_tweet_17          negative                        0.6705   \n",
       "\n",
       "    negativereason_confidence         airline  retweet_count  \\\n",
       "3                      0.7033  Virgin America            0.0   \n",
       "4                      1.0000  Virgin America            0.0   \n",
       "5                      0.6842  Virgin America            0.0   \n",
       "12                     0.3684  Virgin America            0.0   \n",
       "16                     0.3614  Virgin America            0.0   \n",
       "\n",
       "                                                 text  \n",
       "3   virginamerica realli aggress blast obnoxi ente...  \n",
       "4                  virginamerica realli big bad thing  \n",
       "5   virginamerica serious would pay 30 flight seat...  \n",
       "12          virginamerica sfo - pdx schedul still mia  \n",
       "16  virginamerica first fare may three time carrie...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No. of words in the text ##\n",
    "df[\"num_words\"] = df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "df2[\"num_words\"] = df2[\"text\"].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of unique words in the text ##\n",
    "df[\"num_unique_words\"] = df[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "df2[\"num_unique_words\"] = df2[\"text\"].apply(lambda x: len(set(str(x).split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of characters in the text ##\n",
    "df[\"num_chars\"] = df[\"text\"].apply(lambda x: len(str(x)))\n",
    "df2[\"num_chars\"] = df2[\"text\"].apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of stopwords in the text ##\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "df[\"num_stopwords\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "df2[\"num_stopwords\"] = df2[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of punctuations in the text ##\n",
    "import string\n",
    "\n",
    "df[\"num_punctuations\"] =df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "df2[\"num_punctuations\"] =df2['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of title case words in the text ##\n",
    "df[\"num_words_upper\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "df2[\"num_words_upper\"] = df2[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of title case words in the text ##\n",
    "df[\"num_words_title\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "df2[\"num_words_title\"] = df2[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Average length of the words in the text ##\n",
    "df[\"mean_word_len\"] = df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "df2[\"mean_word_len\"] = df2[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>num_words_upper</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tr_tweet_4</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica realli aggress blast obnoxi ente...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tr_tweet_5</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica realli big bad thing</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tr_tweet_6</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica serious would pay 30 flight seat...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tr_tweet_13</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica sfo - pdx schedul still mia</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tr_tweet_17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.3614</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica first fare may three time carrie...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "3    Tr_tweet_4          negative                        1.0000   \n",
       "4    Tr_tweet_5          negative                        1.0000   \n",
       "5    Tr_tweet_6          negative                        1.0000   \n",
       "12  Tr_tweet_13          negative                        0.6842   \n",
       "16  Tr_tweet_17          negative                        0.6705   \n",
       "\n",
       "    negativereason_confidence         airline  retweet_count  \\\n",
       "3                      0.7033  Virgin America            0.0   \n",
       "4                      1.0000  Virgin America            0.0   \n",
       "5                      0.6842  Virgin America            0.0   \n",
       "12                     0.3684  Virgin America            0.0   \n",
       "16                     0.3614  Virgin America            0.0   \n",
       "\n",
       "                                                 text  num_words  \\\n",
       "3   virginamerica realli aggress blast obnoxi ente...         11   \n",
       "4                  virginamerica realli big bad thing          5   \n",
       "5   virginamerica serious would pay 30 flight seat...         14   \n",
       "12          virginamerica sfo - pdx schedul still mia          7   \n",
       "16  virginamerica first fare may three time carrie...         10   \n",
       "\n",
       "    num_unique_words  num_chars  num_stopwords  num_punctuations  \\\n",
       "3                 11         81              0                 1   \n",
       "4                  5         34              0                 0   \n",
       "5                 14         77              1                 1   \n",
       "12                 7         41              0                 1   \n",
       "16                10         65              0                 0   \n",
       "\n",
       "    num_words_upper  num_words_title  mean_word_len  \n",
       "3                 0                0       6.454545  \n",
       "4                 0                0       6.000000  \n",
       "5                 0                0       4.571429  \n",
       "12                0                0       5.000000  \n",
       "16                0                0       5.600000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id   3298\n",
      "airline_sentiment   3\n",
      "airline_sentiment_confidence   516\n",
      "negativereason_confidence   730\n",
      "airline   2\n",
      "retweet_count   5\n",
      "text   3265\n",
      "num_words   29\n",
      "num_unique_words   23\n",
      "num_chars   118\n",
      "num_stopwords   8\n",
      "num_punctuations   11\n",
      "num_words_upper   1\n",
      "num_words_title   1\n",
      "mean_word_len   406\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i,' ',df[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['num_words','num_unique_words','num_chars','num_stopwords','num_punctuations','num_words_upper','num_words_title','mean_word_len'],axis=1,inplace=True)\n",
    "\n",
    "df2.drop(['num_words','num_unique_words','num_chars','num_stopwords','num_punctuations','num_words_upper','num_words_title','mean_word_len'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['airline_sentiment']\n",
    "\n",
    "df.drop('airline_sentiment',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train=df['text'].astype(str)\n",
    "texts_test=df2['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=5000)\n",
    "full_tfidf_word=word_vectorizer.fit_transform(df['text'].values.tolist() + df2['text'].values.tolist())\n",
    "train_tfidf_word = word_vectorizer.transform(df['text'].values.tolist())\n",
    "test_tfidf_word = word_vectorizer.transform(df2['text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index()\n",
    "df2=df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_comp = 20\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "svd_obj.fit(full_tfidf_word)\n",
    "train_svd_word = pd.DataFrame(svd_obj.transform(train_tfidf_word))\n",
    "test_svd_word = pd.DataFrame(svd_obj.transform(test_tfidf_word))\n",
    "    \n",
    "train_svd_word.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "test_svd_word.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "df = pd.concat([df, train_svd_word], axis=1)\n",
    "df2 = pd.concat([df2, test_svd_word], axis=1)\n",
    "del full_tfidf_word, train_tfidf_word, test_tfidf_word, train_svd_word, test_svd_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>svd_word_0</th>\n",
       "      <th>svd_word_1</th>\n",
       "      <th>svd_word_2</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_word_10</th>\n",
       "      <th>svd_word_11</th>\n",
       "      <th>svd_word_12</th>\n",
       "      <th>svd_word_13</th>\n",
       "      <th>svd_word_14</th>\n",
       "      <th>svd_word_15</th>\n",
       "      <th>svd_word_16</th>\n",
       "      <th>svd_word_17</th>\n",
       "      <th>svd_word_18</th>\n",
       "      <th>svd_word_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Tr_tweet_4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>virginamerica realli aggress blast obnoxi ente...</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.068515</td>\n",
       "      <td>0.097654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022569</td>\n",
       "      <td>0.034305</td>\n",
       "      <td>-0.006985</td>\n",
       "      <td>0.041204</td>\n",
       "      <td>-0.107969</td>\n",
       "      <td>0.083326</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.014023</td>\n",
       "      <td>-0.029672</td>\n",
       "      <td>-0.031776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    tweet_id  airline_sentiment_confidence  negativereason_confidence  \\\n",
       "0      3  Tr_tweet_4                           1.0                     0.7033   \n",
       "\n",
       "          airline  retweet_count  \\\n",
       "0  Virgin America            0.0   \n",
       "\n",
       "                                                text  svd_word_0  svd_word_1  \\\n",
       "0  virginamerica realli aggress blast obnoxi ente...    0.021811    0.068515   \n",
       "\n",
       "   svd_word_2     ...       svd_word_10  svd_word_11  svd_word_12  \\\n",
       "0    0.097654     ...         -0.022569     0.034305    -0.006985   \n",
       "\n",
       "   svd_word_13  svd_word_14  svd_word_15  svd_word_16  svd_word_17  \\\n",
       "0     0.041204    -0.107969     0.083326     0.016668     0.014023   \n",
       "\n",
       "   svd_word_18  svd_word_19  \n",
       "0    -0.029672    -0.031776  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>svd_word_0</th>\n",
       "      <th>svd_word_1</th>\n",
       "      <th>svd_word_2</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_word_10</th>\n",
       "      <th>svd_word_11</th>\n",
       "      <th>svd_word_12</th>\n",
       "      <th>svd_word_13</th>\n",
       "      <th>svd_word_14</th>\n",
       "      <th>svd_word_15</th>\n",
       "      <th>svd_word_16</th>\n",
       "      <th>svd_word_17</th>\n",
       "      <th>svd_word_18</th>\n",
       "      <th>svd_word_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Test_tweet_1</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.651909</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica realli miss prime opportun men w...</td>\n",
       "      <td>0.021686</td>\n",
       "      <td>0.080809</td>\n",
       "      <td>0.10867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01339</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>-0.018556</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>-0.012101</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.017618</td>\n",
       "      <td>-0.002198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      tweet_id  airline_sentiment_confidence  \\\n",
       "0      0  Test_tweet_1                         0.634   \n",
       "\n",
       "   negativereason_confidence         airline  retweet_count  \\\n",
       "0                   0.651909  Virgin America              0   \n",
       "\n",
       "                                                text  svd_word_0  svd_word_1  \\\n",
       "0  virginamerica realli miss prime opportun men w...    0.021686    0.080809   \n",
       "\n",
       "   svd_word_2     ...       svd_word_10  svd_word_11  svd_word_12  \\\n",
       "0     0.10867     ...          -0.01339     0.007645    -0.018556   \n",
       "\n",
       "   svd_word_13  svd_word_14  svd_word_15  svd_word_16  svd_word_17  \\\n",
       "0     0.005607    -0.012101    -0.000568     0.007777     0.001092   \n",
       "\n",
       "   svd_word_18  svd_word_19  \n",
       "0     0.017618    -0.002198  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df.drop(['index','text','tweet_id'],axis=1)\n",
    "test=df2.drop(['index','text','tweet_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_map = {'Virgin America':1, 'United':2}\n",
    "\n",
    "train['airline'] = train['airline'].map(airline_map)\n",
    "test['airline'] = test['airline'].map(airline_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb=lgb.LGBMClassifier()\n",
    "\n",
    "lgb.fit(train,y)\n",
    "pred=lgb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['pred']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    336\n",
       "neutral      31\n",
       "positive      4\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dutta\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "negative    43\n",
       "neutral     31\n",
       "positive     4\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.ix[df2['negativereason_confidence']<0.5]['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions=pd.DataFrame(columns=['tweet_id', 'airline_sentiment'])\n",
    "submissions['tweet_id']=df2['tweet_id']\n",
    "submissions['airline_sentiment']=pred\n",
    "submissions.to_csv('tweet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
